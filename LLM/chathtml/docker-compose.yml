services:
    ollama: 
      image: ollama/ollama:latest
      container_name: ollama
      ports:
        - "11435:11434"
      healthcheck:
        test: ollama list || exit 1
        interval: 10s
        timeout: 30s
        retries: 5
        start_period: 5s
      volumes:
        - ./ollama/ollama:/root/.ollama
      networks:
        - ollama_network

    ollama-models-pull:
      container_name: ollama-models-pull
      image: curlimages/curl:latest
      # command: >
      #   http://ollama:11434/api/pull -d '{"name":"llama3.2"}'
      command: >
        /bin/sh -c "
          curl -X POST http://ollama:11434/api/pull -d '{\"name\":\"all-minilm:33m-l12-v2-fp16\"}' &&
          curl -X POST http://ollama:11434/api/pull -d '{\"name\":\"llama3.2\"}' &&
          curl -X POST http://ollama:11434/api/pull -d '{\"name\":\"granite3.1-dense:2b\"}' 
        "
      depends_on:
        ollama:
          condition: service_healthy
      networks:
        - ollama_network

    app:
        build:
            context: .
            dockerfile: ./Dockerfile
        container_name: appstreamlitchat
        image: streamlitchat
        environment:
          - OLLAMA_HOST=http://ollama:11434
        depends_on:
          ollama-models-pull:
            condition: service_completed_successfully        
          ollama:
            condition: service_healthy
        networks:
          - ollama_network
        ports:
            - 8002:8002            
        volumes:
            - ./app:/usr/app:rw

networks:
    ollama_network:
        driver: bridge